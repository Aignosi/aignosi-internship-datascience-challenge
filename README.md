# 1. Bem-vindo ao repositório do Desafio de Dados da aignosi

Esse repositório contém todas as informações e diretrizes necessárias para que você possa realizar o nosso desafio, como parte integrante do nosso processo de avaliação dos potenciais candidatos as vagas estágio em Engenharia de Dados.

Sugerimos que você **leia com bastante atenção** a todos as etapas, critérios e requisitos a serem cumpridos no desafio.

## 1.1 Objetivo do desafio

Avaliar de forma **qualitativa** quais são os pontos fortes e os pontos de gaps do candidato à vaga.
O desafio tem o intuito de prover para o RH e os líderes da aignosi, informações sobre a experiência que você já tem na área. 

## 1.2 Etapas do desafio

O desafio se divide nas seguintes etapas:

1. Recebimento do link de acesso ao repositório (considerando que já cadastramos e liberamos o seu acesso previamente) e credenciais para acesso ao dado noSQL
2. Desenvolvimento do desafio (analisar, explorar e modelar o problema)
3. Criar uma apresentação em **formato PowerPoint**
4. **Submeter** o(s) código(s) e o arquivo da apresentação ao mesmo repositório*(maiores detalhes vide seção 1.6)
5. Informar pelo email eduardo@aignosi.com.br que você concluiu o desafio
6. Iremos combinar uma data da sua apresentação (a ser realizada remotamente via Google Meet)
7. Realizar a apresentação final para os stackholders da aignosi
 
## 1.3 Critérios de avaliação mais relevantes

**Atenção!** Pois os critérios são voltados tanto para as **soft skills** bem como para as **hard skills**.

Iremos avaliar com bastante critério (**em ordem de relevância maior para menor**):
1. **Maturidade na codificação**  
   - Avaliaremos a **organização do código**, o estilo e a qualidade dos comentários.
   - Um código bem estruturado, legível e modular será altamente valorizado.

2. **Maturidade no versionamento do código**  
   - Analisaremos o uso do Git e de boas práticas de versionamento, como commits frequentes e bem descritos.
   - Será considerado o uso adequado de branches e merge requests, além de histórico de mudanças claro.

3. **Nível de organização e sequência lógica de Integração e Armazenamento**  
   - A estruturação e a lógica por trás da transformação dos dados para o armazenamento em um banco relacional.
   - A clareza da arquitetura proposta, bem como a escolha de tecnologias e técnicas adequadas para o processo de ETL.

4. **Maturidade no entendimento dos conceitos fundamentais de engenharia de dados**  
   - Avaliaremos a capacidade de interpretar corretamente os conceitos de engenharia de dados, como manipulação de dados desestruturados, normalização e agregação de dados.
   - Será importante demonstrar discernimento na escolha de ferramentas e métodos apropriados para explorar e transformar os dados.
5. **Skills de comunicação e apresentação**  
   - Durante a apresentação do trabalho, avaliaremos como o candidato comunica suas decisões técnicas aos stakeholders.
   - Espera-se uma explicação clara das escolhas feitas, além de uma apresentação objetiva e compreensível para não técnicos.

6. **Skills em Análise de Dados**  
   - Avaliaremos a qualidade e a clareza dos gráficos e visualizações gerados.
   - Será considerado o quão intuitivas e informativas são as interpretações dos dados, demonstrando capacidade de análise crítica e exploração visual eficaz.

## 1.4 Critérios que **Não nos preocupamos tanto** nessa etapa

**Capacidade em explorar dados de maneira coerente** 

É isso mesmo que você está lendo! Parece contraintuitivo, mas não estamos preocupado em você conseguir fazer uma integração de dados (ETL), então, não há necessidade de se preocupar com isso e gastar todo o tempo do desafio com isso. 

**Esperamos que você faça um EDA (exploratory data analysis)** bacana, mas não "frite" os neurônios. Lembre dos principais critérios que estamos nos preocupando mais em te avaliar, conforme descrito no item anterior.


## 1.5 Requisitos mínimos

Para realizar o desafio, você precisa **cumprir os seguintes requisitos**:

### Requisitos Mínimos Técnicos:
1. **Conhecimento básico de MongoDB**  
   - Saber conectar ao MongoDB, explorar coleções e realizar consultas básicas.
2. **Python para manipulação de dados**  
   - Capacidade de utilizar bibliotecas como Pandas ou ferramentas equivalentes para transformação de dados.
3. **Noções básicas de bancos de dados relacionais (SQL)**  
   - Entendimento de como migrar dados para um banco de dados relacional e realizar consultas SQL básicas.

4. **Conhecimento em versionamento de código (Git)**  
   - Saber criar um repositório, fazer commits frequentes e descrever as mudanças de forma clara.

5. Apresentação em formato PowerPoint

### Requisitos Mínimos de Soft Skills:
1. **Organização e clareza na comunicação**  
   - Capacidade de documentar o código e explicar decisões técnicas de forma clara.

2. **Capacidade de trabalhar com prazos e entregas**  
   - Entrega pontual do desafio, seguindo as instruções fornecidas.

3. **Colaboração e capacidade de aprender**  
   - Disposição para receber feedback e fazer melhorias no código, além de demonstrar proatividade na busca por soluções.

## 1.6 Entregáveis, Prazos e Submissão final

### Entregáveis:
1. **Código-fonte**  
   - Um repositório Git com o código desenvolvido. O repositório deve conter:
     - O script ou notebook utilizado para as etapas de exploração, transformação e análise dos dados.
     - Comentários e documentação explicando o funcionamento do código.
     - Arquivos de configuração necessários (por exemplo, requirements.txt ou environment.yml para dependências).

2. **Relatório ou documentação**  
   - Um relatório ou README explicando as abordagens utilizadas, desafios encontrados e as soluções propostas.
   - Deve conter uma descrição das etapas de integração e armazenamento, além das respostas às perguntas de análise de dados.

3. **Visualizações e análises**  
   - Gráficos e visualizações de dados, quando aplicável, para as perguntas de análise de dados.
   - Capturas de tela ou links para gráficos gerados.

4. **Scripts de integração (opcional)**  
   - Se aplicável, forneça scripts de automação para a etapa de integração com o banco de dados relacional.
### Prazos:
- **Prazo de entrega:**  
  O prazo para entrega do desafio é de **até 03 semanas**, a contar a partir da data em que você recebeu o e-mail de convocação para o desafio.
  
- **Apresentação final:**  
  A data final da apresentação será combinada via e-mail com o time responsável.

### Submissão Final:
- A submissão final deve ser feita via **GitHub** ou qualquer outro sistema de versionamento de sua escolha, com acesso ao repositório fornecido por e-mail ou outro canal especificado.
- Certifique-se de que o repositório esteja público ou compartilhe as permissões adequadas para que a avaliação possa ser realizada sem problemas.
- O relatório e a documentação devem estar disponíveis no repositório Git (README ou um arquivo separado).

## 1.7 FAQ

1. Pode usar Google, Stackoverflow à vontade, pois é assim que funciona na vida real!
2. Será permitido tirar dúvidas com as pessoas da aignosi, apenas no que concerne ao entendimento da dinâmica do desafio. Não é permitido tirar dúvidas técnicas. O contato será via email eduardo@aignosi.com
3. Não é permitido entregar os códigos em formato *.ipynb, pois queremos ver a sua desenvoltura codificando apenas em formato *.py.

##--------------------------------------------------------------------------------------------------------------

# 2. Maiores Detalhes sobre o problema que você irá resolver no desafio
Nessa seção iremos trazer mais informações sobre o problema de negócio que você resolverá, os objetivos de negócio, bem como o que os tomadores de decisão estão esperando dessa solução.

## 2.1 Descrevendo o cenário e o problema

Imagine que você trabalha em uma empresa que fornece serviços de engenharia de dados para a indústria, e você é o principal engenheiro de dados desse time. Considere também que é a primeira vez que você e sua empresa estão encarando um desafio de integração de dados para esse cliente específico.

Ou seja, você conhece pouco sobre o processo atual de integração e tratamento de dados do cliente, não sabe muito bem como ele toma as decisões sobre o pipeline de dados ou as ferramentas que utiliza atualmente. Porém, por "sorte", o cliente é bem camarada e está disposto a correr um certo risco com o projeto. Ou seja, mesmo que o pipeline de ETL ou a integração de dados não fique perfeita, ele precisa acreditar que vale a pena continuar explorando o problema. Se o projeto não sair como esperado, o cliente pode estar aberto a explorar outras abordagens de ETL e integração de dados no futuro.

Você tem, portanto, a oportunidade de mostrar para esse cliente que a integração de dados é potencialmente viável e valiosa para o negócio dele. É uma chance de impressionar e convencê-lo de que a exploração de dados pode abrir portas para novos insights e decisões estratégicas.

Dito isso, uma dica importante: preocupe-se em avaliar bem os dados que você tem em mãos, explique claramente as escolhas das técnicas de exploração e transformação dos dados, e capriche numa apresentação impactante, de forma que o seu cliente, que não é especialista em dados, possa entender o pipeline que você está propondo e ver o valor que isso pode trazer. Seu objetivo é fazer o cliente pensar: "Existe um grande potencial nesses dados, vale a pena investir!"

Portanto, reforçando: não se preocupe em criar um modelo preditivo para este desafio. O foco é mostrar um processo sólido de ETL e integração de dados.

Mais detalhes sobre o cliente: é uma empresa da indústria mineradora, e o seu contato direto, que está comprando o projeto piloto, tem uma leve noção de análise de dados.

## 2.2 O Dado

O dado do problema a ser analisado se encontra na plataforma MongoDB, as credenciais de acesso seram eviadas por email ao candidato.


## 2.3 Considerações Finais

Busque trazer **diferenciais** para o seu desafio:

1. **Formular suas hipóteses sobre a integração e transformação dos dados**  
   - Documente suas hipóteses e expectativas sobre o processo de ETL e tratamento de dados. Por exemplo, explique se você acredita que os dados precisam ser normalizados, agregados ou transformados de alguma maneira específica.

2. **Descrever o que você observa nos dados brutos**  
   - Quais padrões ou irregularidades você percebe nos dados antes da transformação? Há inconsistências, dados ausentes, duplicados ou algum tipo de outlier que você precisou tratar? 

3. **Descrever as técnicas de transformação de dados que utilizou**  
   - Explique por que você escolheu uma técnica de ETL em detrimento de outra. Exemplo: "Optei por normalizar os dados desta maneira porque isso facilita a análise subsequente" ou "Utilizei agregação porque os dados estavam fragmentados em várias coleções."

4. **Justificar a escolha das features (campos) selecionados para armazenamento ou análise**  
   - Explique como você escolheu os atributos ou features mais relevantes e por que decidiu armazená-los em um banco de dados relacional ou outra estrutura de dados.

5. **Descrever possíveis melhorias ou extensões**  
   - Mesmo que o foco não seja a criação de modelos preditivos, comente sobre como você poderia expandir o pipeline de dados no futuro. Se fosse necessário aplicar algum tipo de análise mais avançada, como faria isso? Que tipo de modelo ou análise adicional você usaria para gerar insights mais profundos a partir dos dados transformados?


## 2.4 Agradecimentos e dúvidas

Agradecemos o seu interesse de participar no desafio e qualquer dúvida, entre em contato pelo email com eduardo@aignosi.com.br
